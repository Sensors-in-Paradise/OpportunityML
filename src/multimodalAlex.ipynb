{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import settings as settings\n",
    "import pandas as pd\n",
    "from evaluation.metrics import accuracy\n",
    "from evaluation.conf_matrix import create_conf_matrix\n",
    "from loader.Preprocessor import Preprocessor\n",
    "from models.JensModel import JensModel\n",
    "from models.RainbowModel import RainbowModel\n",
    "from models.ResNetModel import ResNetModel\n",
    "from models.ResNetModel_Multimodal import ResNetModelMultimodal\n",
    "from utils.filter_activities import filter_activities\n",
    "from utils.folder_operations import new_saved_experiment_folder\n",
    "from utils.DataConfig import Sonar22CategoriesConfig, OpportunityConfig, SonarConfig, LabPoseConfig\n",
    "from tensorflow.keras.layers import (Dense)\n",
    "from utils.Recording import Recording\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.DataConfig\n",
    "from pose_sequence_loader import *\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.DataConfig\n",
    "import importlib\n",
    "importlib.reload(utils.DataConfig)\n",
    "from utils.DataConfig import Sonar22CategoriesConfig, OpportunityConfig, SonarConfig, LabPoseConfig\n",
    "\n",
    "# Init\n",
    "# TODO: refactor, find out why confusion matrix sometimes shows different results than accuracy\n",
    "# TODO: - make train and test datasets evenly distributed\n",
    "#       - make \n",
    "\"\"\" \n",
    "Number of recordings per person\n",
    "{'connie.csv': 6, 'alex.csv': 38, 'trapp.csv': 9, 'anja.csv': 13, 'aileen.csv': 52, 'florian.csv': 16, 'brueggemann.csv': 36, 'oli.csv': 20, 'rauche.csv': 9, 'b2.csv': 6, 'yvan.csv': 8, 'christine.csv': 7, 'mathias.csv': 2, 'kathi.csv': 17}\n",
    "\"\"\"\n",
    "\n",
    "data_config = LabPoseConfig(dataset_path='/dhc/groups/bp2021ba1/data/lab_data_filtered_without_null')#OpportunityConfig(dataset_path='/dhc/groups/bp2021ba1/data/opportunity-dataset')\n",
    "#data_config = SonarConfig(dataset_path='/dhc/groups/bp2021ba1/data/lab_data')#OpportunityConfig(dataset_path='/dhc/groups/bp2021ba1/data/opportunity-dataset')\n",
    "settings.init(data_config)\n",
    "random.seed(1678978086101)\n",
    "\n",
    "k_fold_splits = 3\n",
    "numEpochs = 10\n",
    "\n",
    "# LOAD DATA\n",
    "recordings = settings.DATA_CONFIG.load_dataset()#limit=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pose_sequence_loader\n",
    "# import importlib\n",
    "# importlib.reload(pose_sequence_loader)\n",
    "\n",
    "# from pose_sequence_loader import *\n",
    "# from multiprocessing import Pool\n",
    "# import tqdm\n",
    "\n",
    "def process_recording(recording_with_index):\n",
    "    i = recording_with_index[0]\n",
    "    recording = recording_with_index[1]\n",
    "    pose_frame = get_poseframe(recording, \"/dhc/groups/bp2021ba1/data/lab_data\")\n",
    "    \n",
    "    print(f\"Pose Frame added to Recording {i+1}/{len(recordings)}  \")\n",
    "    return pose_frame\n",
    "\n",
    "# pose_frames = []\n",
    "# for i, k in list(enumerate(recordings)):\n",
    "#     pose_frames.append(process_recording((i,k)))\n",
    "\n",
    "pool = Pool()\n",
    "pose_frames = pool.map(process_recording, list(enumerate(recordings)), 1)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for i, pose_frame in enumerate(pose_frames):\n",
    "    recordings[i].pose_frame = pose_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialLength = len(recordings)\n",
    "recordings = list(filter(\n",
    "    lambda recording: not recording.pose_frame.empty, \n",
    "    recordings\n",
    "))\n",
    "print(f\"Filtered out {initialLength - len(recordings)} Recordings (!)\")\n",
    "\n",
    "print(\"==> APPENDING POSE FRAMES DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG TRAINING\n",
    "window_size = 100\n",
    "n_sensor_features = recordings[0].sensor_frame.shape[1]\n",
    "n_pose_features = recordings[0].pose_frame.shape[1]\n",
    "print(f\"Sensor features: {n_sensor_features},  Pose features: {n_pose_features}\")\n",
    "n_outputs = settings.DATA_CONFIG.n_activities()\n",
    "\n",
    "# Create Folder, save model export and evaluations there\n",
    "experiment_folder_path = new_saved_experiment_folder(\n",
    "    \"multimodalAlex\"\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate(y_test_pred: np.ndarray, y_test_true: np.ndarray, confusionMatrixFileName=None, confusionMatrixTitle=\"\") -> tuple[float, float,float, np.ndarray]:\n",
    "    acc = accuracy(y_test_pred, y_test_true)\n",
    "    if confusionMatrixFileName:\n",
    "        create_conf_matrix(experiment_folder_path, y_test_pred, y_test_true, file_name = confusionMatrixFileName, title=confusionMatrixTitle+\", acc:\"+str(int(acc*10000)/100)+\"%\") \n",
    "    f1_macro = f1_score(np.argmax(y_test_true, axis=1), np.argmax(y_test_pred, axis=1), average=\"macro\")   \n",
    "    f1_weighted = f1_score(np.argmax(y_test_true, axis=1), np.argmax(y_test_pred, axis=1), average=\"weighted\")    \n",
    "    return acc, f1_macro, f1_weighted, y_test_true\n",
    "\n",
    "def instanciateModel(use_sensor_frame = True, use_pose_frame = False) -> ResNetModelMultimodal:\n",
    "    n_features = 0\n",
    "    n_features += n_sensor_features if (use_sensor_frame) else 0\n",
    "    n_features += n_pose_features if (use_pose_frame) else 0\n",
    "\n",
    "    return ResNetModelMultimodal(\n",
    "        n_epochs=numEpochs,\n",
    "        window_size=100,\n",
    "        n_features=n_features,\n",
    "        n_outputs=n_outputs,\n",
    "        batch_size=64,\n",
    "        use_sensor_frame=use_sensor_frame,\n",
    "        use_pose_frame=use_pose_frame\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND PREDICT\n",
    "multiModals = [(True, False), (True, True), (False, True)]\n",
    "for modality_index, (use_sensor_frame, use_pose_frame) in enumerate(multiModals):\n",
    "    model = instanciateModel(use_sensor_frame=use_sensor_frame, use_pose_frame=use_pose_frame)\n",
    "    model.n_epochs = numEpochs\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=k_fold_splits, random_state=None)\n",
    "    split_index = int(0.8 * len(recordings))\n",
    "    recordingsTrain = recordings[:split_index]\n",
    "    recordingsTest = recordings[split_index+1:]\n",
    "\n",
    "    x_train, y_train = model.windowize_convert_fit(recordingsTrain)\n",
    "\n",
    "    x_test, y_test = model.windowize_convert(recordingsTest)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    acc, f1_macro, f1_weighted, _ = evaluate(y_test_pred, y_test)\n",
    "\n",
    "    print(f\"==== Sensor Features: {use_sensor_frame}   Pose Features: {use_pose_frame} ====\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"F1 Macro: {f1_macro}\")\n",
    "    print(f\"F1 Weighted: {f1_weighted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for recording in recordings:\n",
    "#    print(recording.sensor_frame.shape[0], recording.pose_frame.shape[0], recording.time_frame.shape[0], recording.activities.shape[0])\n",
    "\n",
    "#print(recordings[0].pose_frame)\n",
    "\n",
    "import models.ResNetModel_Multimodal\n",
    "import importlib\n",
    "importlib.reload(models.ResNetModel_Multimodal)\n",
    "\n",
    "from models.ResNetModel_Multimodal import ResNetModelMultimodal"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2171cf73acafe344dfae972adc9cb578812877998169c8a7c19a1c4d43d1a332"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('alex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
