{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import settings as settings\n",
    "import pandas as pd\n",
    "from evaluation.metrics import accuracy\n",
    "from evaluation.conf_matrix import create_conf_matrix\n",
    "from loader.Preprocessor import Preprocessor\n",
    "from models.JensModel import JensModel\n",
    "from models.RainbowModel import RainbowModel\n",
    "from models.ResNetModel import ResNetModel\n",
    "from models.ResNetModel_Multimodal import ResNetModelMultimodal\n",
    "from models.LeanderDeepConvLSTM import LeanderDeepConvLSTM\n",
    "from utils.filter_activities import filter_activities\n",
    "from utils.folder_operations import new_saved_experiment_folder\n",
    "from utils.DataConfig import Sonar22CategoriesConfig, OpportunityConfig, SonarConfig, LabPoseConfig\n",
    "from tensorflow.keras.layers import (Dense)\n",
    "from utils.Recording import Recording\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.DataConfig\n",
    "from pose_sequence_loader import *\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.DataConfig\n",
    "import importlib\n",
    "importlib.reload(utils.DataConfig)\n",
    "from utils.DataConfig import Sonar22CategoriesConfig, OpportunityConfig, SonarConfig, LabPoseConfig\n",
    "\n",
    "# Init\n",
    "# TODO: refactor, find out why confusion matrix sometimes shows different results than accuracy\n",
    "# TODO: - make train and test datasets evenly distributed\n",
    "#       - make \n",
    "\"\"\" \n",
    "Number of recordings per person\n",
    "{'connie.csv': 6, 'alex.csv': 38, 'trapp.csv': 9, 'anja.csv': 13, 'aileen.csv': 52, 'florian.csv': 16, 'brueggemann.csv': 36, 'oli.csv': 20, 'rauche.csv': 9, 'b2.csv': 6, 'yvan.csv': 8, 'christine.csv': 7, 'mathias.csv': 2, 'kathi.csv': 17}\n",
    "\"\"\"\n",
    "\n",
    "data_config = LabPoseConfig(dataset_path='/dhc/groups/bp2021ba1/data/lab_data_filtered_without_null')#OpportunityConfig(dataset_path='/dhc/groups/bp2021ba1/data/opportunity-dataset')\n",
    "#data_config = SonarConfig(dataset_path='/dhc/groups/bp2021ba1/data/lab_data')#OpportunityConfig(dataset_path='/dhc/groups/bp2021ba1/data/opportunity-dataset')\n",
    "settings.init(data_config)\n",
    "random.seed(1678978086101)\n",
    "\n",
    "k_fold_splits = 5\n",
    "numEpochs = 10\n",
    "window_size = 600\n",
    "\n",
    "# LOAD DATA\n",
    "recordings = settings.DATA_CONFIG.load_dataset()#limit=3)\n",
    "recordings = Preprocessor().our_preprocess(recordings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pose_sequence_loader\n",
    "# import importlib\n",
    "# importlib.reload(pose_sequence_loader)\n",
    "\n",
    "# from pose_sequence_loader import *\n",
    "# from multiprocessing import Pool\n",
    "# import tqdm\n",
    "\n",
    "def process_recording(recording_with_index):\n",
    "    i = recording_with_index[0]\n",
    "    recording = recording_with_index[1]\n",
    "    pose_frame = get_poseframe(recording, \"/dhc/groups/bp2021ba1/data/lab_data\")\n",
    "    \n",
    "    print(f\"Pose Frame added to Recording {i+1}/{len(recordings)}  \")\n",
    "    return pose_frame\n",
    "\n",
    "# pose_frames = []\n",
    "# for i, k in list(enumerate(recordings)):\n",
    "#     pose_frames.append(process_recording((i,k)))\n",
    "\n",
    "pool = Pool()\n",
    "pose_frames = pool.map(process_recording, list(enumerate(recordings)), 1)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for i, pose_frame in enumerate(pose_frames):\n",
    "    recordings[i].pose_frame = pose_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialLength = len(recordings)\n",
    "recordings = list(filter(\n",
    "    lambda recording: not recording.pose_frame.empty, \n",
    "    recordings\n",
    "))\n",
    "print(f\"Filtered out {initialLength - len(recordings)} Recordings (!)\")\n",
    "\n",
    "print(\"==> APPENDING POSE FRAMES DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG TRAINING\n",
    "n_sensor_features = recordings[0].sensor_frame.shape[1]\n",
    "n_pose_features = recordings[0].pose_frame.shape[1]\n",
    "print(f\"Sensor features: {n_sensor_features},  Pose features: {n_pose_features}\")\n",
    "n_outputs = settings.DATA_CONFIG.n_activities()\n",
    "\n",
    "# Create Folder, save model export and evaluations there\n",
    "experiment_folder_path = new_saved_experiment_folder(\n",
    "    \"multiModal_alex\"\n",
    ")\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def evaluate(y_test_pred: np.ndarray, y_test_true: np.ndarray, confusionMatrixFileName=None, confusionMatrixTitle=\"\") -> tuple[float, float,float, np.ndarray]:\n",
    "    acc = accuracy(y_test_pred, y_test_true)\n",
    "    if confusionMatrixFileName:\n",
    "        create_conf_matrix(\n",
    "            experiment_folder_path, y_test_pred, y_test_true, \n",
    "            file_name = confusionMatrixFileName, title=confusionMatrixTitle+\", acc:\"+str(int(acc*10000)/100)+\"%\"\n",
    "            # label_mapping = {value: key for key, value in data_config.category_labels.items()}\n",
    "    ) \n",
    "    f1_macro = f1_score(np.argmax(y_test_true, axis=1), np.argmax(y_test_pred, axis=1), average=\"macro\")   \n",
    "    f1_weighted = f1_score(np.argmax(y_test_true, axis=1), np.argmax(y_test_pred, axis=1), average=\"weighted\")    \n",
    "    return acc, f1_macro, f1_weighted, y_test_true\n",
    "\n",
    "def save_prediction(y_test_pred: np.ndarray, y_test_true: np.ndarray, acc, f1_macro, f1_weighted, file_name: str):\n",
    "    with open(os.path.join(experiment_folder_path, f\"{file_name}.json\"), \"w+\") as file:\n",
    "        json_dict = {\n",
    "            'Predicted Labels': y_test_pred,\n",
    "            'Actual Lables': y_test_true,\n",
    "            'Accuracy': acc,\n",
    "            'F1 Macro': f1_macro,\n",
    "            'F1 Weighted':f1_weighted\n",
    "        }\n",
    "        \n",
    "        json.dump(json_dict, file, cls=NumpyEncoder)\n",
    "\n",
    "\n",
    "def instanciateModel(use_sensor_frame = True, use_pose_frame = False) -> ResNetModelMultimodal:\n",
    "    n_features = 0\n",
    "    n_features += n_sensor_features if (use_sensor_frame) else 0\n",
    "    n_features += n_pose_features if (use_pose_frame) else 0\n",
    "\n",
    "    #return ResNetModelMultimodal(\n",
    "    return LeanderDeepConvLSTM(\n",
    "        n_epochs=numEpochs,\n",
    "        window_size=window_size,\n",
    "        n_features=n_features,\n",
    "        n_outputs=n_outputs,\n",
    "        batch_size=64,\n",
    "        use_sensor_frame=use_sensor_frame,\n",
    "        use_pose_frame=use_pose_frame,\n",
    "        verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND PREDICT\n",
    "multiModals = [(True, False), (True, True), (False, True)]\n",
    "for modality_index, (use_sensor_frame, use_pose_frame) in enumerate(multiModals):\n",
    "    print(f\"\\n\\n==== Sensor Features: {use_sensor_frame}   Pose Features: {use_pose_frame} ====\")\n",
    "    model = instanciateModel(use_sensor_frame=use_sensor_frame, use_pose_frame=use_pose_frame)\n",
    "    model.n_epochs = numEpochs\n",
    "    model.model.save_weights(\"ckpt\")\n",
    "\n",
    "    confusion_y_test_pred = None\n",
    "    confusion_y_test_actual = None\n",
    "    avg_acc = avg_f1_macro = avg_f1_weighted = divider = 0\n",
    "    k_fold = KFold(n_splits=k_fold_splits, random_state=42, shuffle=True)\n",
    "    for k_fold_index, (train_indices, test_indices) in enumerate(k_fold.split(recordings)):\n",
    "        model.model.load_weights(\"ckpt\")\n",
    "        \n",
    "        recordingsTrain = [recordings[ind] for ind in train_indices.astype(int)]\n",
    "        recordingsTest = [recordings[ind] for ind in test_indices.astype(int)]\n",
    "\n",
    "        x_train, y_train = model.windowize_convert_fit(recordingsTrain)\n",
    "\n",
    "        x_test, y_test_actual = model.windowize_convert(recordingsTest)\n",
    "        y_test_pred = model.predict(x_test)\n",
    "\n",
    "        confusion_y_test_pred = y_test_pred if confusion_y_test_pred is None else np.append(confusion_y_test_pred, y_test_pred, axis=0)\n",
    "        confusion_y_test_actual = y_test_actual if confusion_y_test_actual is None else np.append(confusion_y_test_actual, y_test_actual, axis=0)\n",
    "\n",
    "        acc, f1_macro, f1_weighted, _ = evaluate(\n",
    "            y_test_pred, \n",
    "            y_test_actual\n",
    "        )\n",
    "\n",
    "        weight = len(confusion_y_test_actual)\n",
    "        avg_acc += acc * weight\n",
    "        avg_f1_macro += f1_macro * weight\n",
    "        avg_f1_weighted += f1_weighted * weight\n",
    "        divider += weight\n",
    "\n",
    "        print(f\"=> K-Fold {k_fold_index+1}/{k_fold_splits}: acc: {acc}  f1 macro: {f1_macro}  f1 weighted: {f1_weighted}\\n\")\n",
    "\n",
    "    avg_acc = avg_acc / divider\n",
    "    avg_f1_macro = avg_f1_macro / divider\n",
    "    avg_f1_weighted = avg_f1_weighted / divider\n",
    "\n",
    "    save_prediction(\n",
    "            confusion_y_test_pred, confusion_y_test_actual, \n",
    "            avg_acc, avg_f1_macro, avg_f1_weighted,\n",
    "            f\"Data {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\"\n",
    "        )\n",
    "    _, _, _, _ = evaluate(\n",
    "            confusion_y_test_pred, confusion_y_test_actual, \n",
    "            confusionMatrixFileName=f\"Confusion {'SENSOR' if use_sensor_frame else 'x'} - {'POSE' if use_pose_frame else 'x'}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n\\n==== Results ====\")\n",
    "    print(f\"Accuracy: {avg_acc}\")\n",
    "    print(f\"F1 Macro: {avg_f1_macro}\")\n",
    "    print(f\"F1 Weighted: {avg_f1_weighted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for recording in recordings:\n",
    "#    print(recording.sensor_frame.shape[0], recording.pose_frame.shape[0], recording.time_frame.shape[0], recording.activities.shape[0])\n",
    "\n",
    "#print(recordings[0].pose_frame)\n",
    "\n",
    "# import models.ResNetModel_Multimodal\n",
    "# import importlib\n",
    "# importlib.reload(models.ResNetModel_Multimodal)\n",
    "\n",
    "# from models.ResNetModel_Multimodal import ResNetModelMultimodal\n",
    "\n",
    "import models.LeanderDeepConvLSTM\n",
    "import importlib\n",
    "importlib.reload(models.LeanderDeepConvLSTM)\n",
    "\n",
    "from models.LeanderDeepConvLSTM import LeanderDeepConvLSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array([\n",
    "            0.0,\n",
    "            1.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0,\n",
    "            0.0\n",
    "        ])\n",
    "count = 0\n",
    "for l in list(confusion_y_test_actual):\n",
    "    should_continue = False\n",
    "    for index, ll in enumerate(l):\n",
    "        if label[index] != ll:\n",
    "            should_continue = True\n",
    "    if not should_continue:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings[0].pose_frame.to_csv(\"/dhc/groups/bp2021ba1/alex/UnicornML/src/pose_frame.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2171cf73acafe344dfae972adc9cb578812877998169c8a7c19a1c4d43d1a332"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('alex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
